{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee940a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29175c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#first test round (sufficient)\n",
    "annotations_test = pd.read_csv('DataFrame_PS_20240628.csv')\n",
    "sample_selec_test = pd.read_csv('iaa_first_round.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1 = pd.read_csv('DataFrame_PS_20240710_ann1.csv')\n",
    "ann2 = pd.read_csv('DataFrame_PS_20240710_ann2.csv')\n",
    "ann1['annotator'] = 'annotator1'\n",
    "ann2['annotator'] = 'annotator2'\n",
    "\n",
    "sample_selec1 = pd.read_csv('ann1_first_round.csv')\n",
    "sample_selec2 = pd.read_csv('ann2_first_round.csv')\n",
    "sample_selec = pd.concat([sample_selec1, sample_selec2, sample_selec_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_nrs_1 = list(sample_selec1['note_nr'].unique()) + list(sample_selec_test['note_nr'].unique())\n",
    "note_nrs_2 = list(sample_selec2['note_nr'].unique()) + list(sample_selec_test['note_nr'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sample_selec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_test['note_nr'] = annotations_test['source_file'].replace(['iaa-file105', 'iaa-file134', 'iaa-file143', 'iaa-file15', 'iaa-file153', 'iaa-file161', 'iaa-file172', 'iaa-file186', 'iaa-file202', 'iaa-file26', 'iaa-file70', 'iaa-file85', 'iaa-file88', 'iaa-file96' ], [130897, 36857, 138917, 40048, 42201, 49589, 59783, 59940, 66374, 42295, 113107, 150060, 114600, 130336])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fccda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann1['note_nr'] = ann1['source_file'].str.extract(r'(\\d+)')\n",
    "#ann2['note_nr'] = ann2['source_file'].str.extract(r'(\\d+)')\n",
    "def extract_note_nr(text):\n",
    "    matches = re.findall(r'\\d+', text)\n",
    "    return matches[-1] if matches else None\n",
    "\n",
    "ann1['note_nr'] = ann1['source_file'].apply(extract_note_nr)\n",
    "ann1['note_nr'] = ann1['note_nr'].astype(int)\n",
    "\n",
    "ann2['note_nr'] = ann2['source_file'].apply(extract_note_nr)\n",
    "ann2['note_nr'] = ann2['note_nr'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.concat([ann1, ann2, annotations_test], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dde1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = annotations.dropna(subset=['note_nr'])\n",
    "sample_selec = sample_selec.dropna(subset=['note_nr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6f152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf07bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = annotations.dropna(subset=['note_nr'])\n",
    "sample_selec = sample_selec.dropna(subset=['note_nr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new '_sentence_text' column and fill with snippets\n",
    "def get_snippet(row):\n",
    "    note_nr = row['note_nr']\n",
    "    begin = int(row['begin']) - 60\n",
    "    end = int(row['end']) - 60\n",
    "    \n",
    "    # Look up the note number in sample_selec\n",
    "    censored_text = sample_selec[sample_selec['note_nr'] == note_nr]['censored'].values[0]\n",
    "    \n",
    "    # Get the snippet from the censored text\n",
    "    snippet = censored_text[begin:end]\n",
    "    \n",
    "    return snippet\n",
    "\n",
    "# Rename '_sentence_text' to 'inception_sentence'\n",
    "annotations.rename(columns={'_sentence_text': 'inception_sentence'}, inplace=True)\n",
    "annotations['_sentence_text'] = annotations.apply(get_snippet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_selec['sentences'] = sample_selec['censored'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator1 = annotations[annotations['annotator'] == 'annotator1']\n",
    "annotator2 = annotations[annotations['annotator'] == 'annotator2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def find_match(annotator1, note_nr, sentence, sentence_context, sentences, i, threshold=90):\n",
    "    def is_fuzzy_match(text1, text2, threshold=90):\n",
    "        return fuzz.partial_ratio(text1, text2) >= threshold\n",
    "    \n",
    "    match = annotator1[(annotator1['note_nr'] == note_nr) & \n",
    "                       (annotator1['_sentence_text'].apply(lambda x: is_fuzzy_match(x, sentence)) |\n",
    "                        annotator1['_sentence_text'].apply(lambda x: is_fuzzy_match(x, sentence_context)) |\n",
    "                        annotator1['_sentence_text'].apply(lambda x: is_fuzzy_match(sentence, x)) |\n",
    "                        annotator1['_sentence_text'].apply(lambda x: (\n",
    "                            is_fuzzy_match(x[:10], sentence) and (i-1 >= 0 and is_fuzzy_match(x[10:], sentences[i-1]))\n",
    "                        ) or (\n",
    "                            is_fuzzy_match(x[-10:], sentence) and (i+1 < len(sentences) and is_fuzzy_match(x[:-10], sentences[i+1]))\n",
    "                        )))]\n",
    "\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db555e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Assuming sample_selec and annotator1 are already defined DataFrames\n",
    "\n",
    "# Copy sample_selec to annotator1_results\n",
    "annotator1_results = copy.deepcopy(sample_selec)\n",
    "\n",
    "# Create a new column 'manual_sentence_labels' by copying the 'sentences' column\n",
    "annotator1_results['manual_sentence_labels'] = annotator1_results['sentences'].copy()\n",
    "\n",
    "# Iterate over the rows in annotator1_results\n",
    "for idx, row in annotator1_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    if note_nr in annotator1['note_nr'].values:\n",
    "        # Get the corresponding sentences for the note_nr\n",
    "        sentences = row['manual_sentence_labels']\n",
    "        updated_sentences = []\n",
    "#         for sentence in sentences:\n",
    "#             print('sentence:', sentence)\n",
    "#             match = annotator1[(annotator1['note_nr'] == note_nr) & (annotator1['_sentence_text'] == sentence)]\n",
    "#             if not match.empty:\n",
    "#                 updated_sentences.append(match['WHOPS'].values[0])\n",
    "#             else:\n",
    "#                 updated_sentences.append(np.nan)\n",
    "        for i in range(len(sentences)):\n",
    "            sentence = sentences[i]\n",
    "            # Initialize an empty list to hold the valid sentences\n",
    "            context = []\n",
    "            # Check if sentences[i-1] exists\n",
    "            if i - 1 >= 0:\n",
    "                context.append(sentences[i-1])\n",
    "            # Add sentences[i] (it is assumed that sentences[i] always exists)\n",
    "            context.append(sentences[i])\n",
    "            # Check if sentences[i+1] exists\n",
    "            if i + 1 < len(sentences):\n",
    "                context.append(sentences[i+1])\n",
    "            # Join the valid sentences with spaces\n",
    "            sentence_context = '.'.join(context)\n",
    "            #print('sentence:', sentence)\n",
    "            #print('sentence_context', sentence_context)\n",
    "            # Find the match using the function\n",
    "            result = find_match(annotator1, note_nr, sentence, sentence_context, sentences, i)\n",
    "\n",
    "            # Append the corresponding value or np.nan to updated_sentences\n",
    "            if not result.empty:\n",
    "                updated_sentences.append(result['WHOPS'].values[0])\n",
    "            else:\n",
    "                updated_sentences.append(np.nan)\n",
    "        # Update the 'manual_sentence_labels' column with the new values\n",
    "        annotator1_results.at[idx, 'manual_sentence_labels'] = updated_sentences\n",
    "\n",
    "# Iterate over the rows in annotator1_results again to update non-annotated sentences\n",
    "for idx, row in annotator1_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    sentences = row['manual_sentence_labels']\n",
    "    if all(isinstance(s, str) for s in sentences):\n",
    "        match = annotator1[annotator1['note_nr'] == note_nr]\n",
    "        if match.empty:\n",
    "            annotator1_results.at[idx, 'manual_sentence_labels'] = [np.nan] * len(sentences)\n",
    "\n",
    "# Update 'None' labels to np.nan in 'manual_sentence_labels'\n",
    "annotator1_results['manual_sentence_labels'] = annotator1_results['manual_sentence_labels'].apply(\n",
    "    lambda x: [np.nan if v is None else v for v in x]\n",
    ")\n",
    "\n",
    "# Replace 'WHO 0', 'WHO 1', etc. with the corresponding integer number in 'manual_sentence_labels'\n",
    "annotator1_results['manual_sentence_labels'] = annotator1_results['manual_sentence_labels'].apply(\n",
    "    lambda x: [int(v.split()[1]) if isinstance(v, str) and v.startswith(\"WHO\") else v for v in x]\n",
    ")\n",
    "\n",
    "# Copy 'manual_sentence_labels' to 'relevance_manual' and replace values\n",
    "annotator1_results['relevance_manual'] = annotator1_results['manual_sentence_labels'].apply(\n",
    "    lambda x: ['irrelevant' if isinstance(v, float) and np.isnan(v) else 'relevant' for v in x]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "annotator1_results['note_PS_manual'] = np.nan\n",
    "\n",
    "# Iterate over the rows in annotator1_results\n",
    "for idx, row in annotator1_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    # Look up the rows in annotator1 with the same note_nr\n",
    "    matches = annotator1[annotator1['note_nr'] == note_nr]\n",
    "    # Check if any of these rows contain 'report_type' in the 'sentence_text' column\n",
    "    report_type_match = matches[matches['inception_sentence'].str.contains('report_type', na=False)]\n",
    "    if not report_type_match.empty:\n",
    "        # Assign the value from the 'WHOPS' column of the first matching row to 'note_PS_manual'\n",
    "        annotator1_results.at[idx, 'note_PS_manual'] = report_type_match['WHOPS'].values[0]\n",
    "\n",
    "        \n",
    "        \n",
    "# Convert 'WHO 0', 'WHO 1', etc. in 'note_PS_manual' to their corresponding integers and ensure NaN values are np.nan\n",
    "annotator1_results['note_PS_manual'] = annotator1_results['note_PS_manual'].apply(\n",
    "    lambda x: int(x.split()[1]) if isinstance(x, str) and x.startswith(\"WHO\") else np.nan\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Copy the 'note_PS_manual' column and replace values\n",
    "annotator1_results['relevance_PS_manual'] = annotator1_results['note_PS_manual'].apply(\n",
    "    lambda x: 'irrelevant' if np.isnan(x) else 'relevant'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the new column 'previous_ann' initialized with 'no'\n",
    "annotator1_results['previous_ann'] = 'no'\n",
    "\n",
    "# Iterate over the rows in annotator1_results\n",
    "for idx, row in annotator1_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    # Look up the rows in annotator1 with the same note_nr\n",
    "    matches = annotator1[annotator1['note_nr'] == note_nr]\n",
    "    # Check if any of these rows contain 'WHO PS already annotated' in the 'WHOPScat' column\n",
    "    if any(matches['WHOPScat'].str.contains('WHO PS already annotated', na=False)):\n",
    "        annotator1_results.at[idx, 'previous_ann'] = 'yes'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11bcf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Assuming sample_selec and annotator2 are already defined DataFrames\n",
    "\n",
    "# Copy sample_selec to annotator2_results\n",
    "annotator2_results = copy.deepcopy(sample_selec)\n",
    "\n",
    "# Create a new column 'manual_sentence_labels' by copying the 'sentences' column\n",
    "annotator2_results['manual_sentence_labels'] = annotator2_results['sentences'].copy()\n",
    "\n",
    "# Iterate over the rows in annotator2_results\n",
    "for idx, row in annotator2_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    if note_nr in annotator2['note_nr'].values:\n",
    "        # Get the corresponding sentences for the note_nr\n",
    "        sentences = row['manual_sentence_labels']\n",
    "        updated_sentences = []\n",
    "#         for sentence in sentences:\n",
    "#             print('sentence:', sentence)\n",
    "#             match = annotator1[(annotator1['note_nr'] == note_nr) & (annotator1['_sentence_text'] == sentence)]\n",
    "#             if not match.empty:\n",
    "#                 updated_sentences.append(match['WHOPS'].values[0])\n",
    "#             else:\n",
    "#                 updated_sentences.append(np.nan)\n",
    "        for i in range(len(sentences)):\n",
    "            sentence = sentences[i]\n",
    "            # Initialize an empty list to hold the valid sentences\n",
    "            context = []\n",
    "            # Check if sentences[i-1] exists\n",
    "            if i - 1 >= 0:\n",
    "                context.append(sentences[i-1])\n",
    "            # Add sentences[i] (it is assumed that sentences[i] always exists)\n",
    "            context.append(sentences[i])\n",
    "            # Check if sentences[i+1] exists\n",
    "            if i + 1 < len(sentences):\n",
    "                context.append(sentences[i+1])\n",
    "            # Join the valid sentences with spaces\n",
    "            sentence_context = '.'.join(context)\n",
    "            #print('sentence:', sentence)\n",
    "            #print('sentence_context', sentence_context)\n",
    "            # Find the match using the function\n",
    "            result = find_match(annotator2, note_nr, sentence, sentence_context, sentences, i)\n",
    "\n",
    "            # Append the corresponding value or np.nan to updated_sentences\n",
    "            if not result.empty:\n",
    "                updated_sentences.append(result['WHOPS'].values[0])\n",
    "            else:\n",
    "                updated_sentences.append(np.nan)\n",
    "        # Update the 'manual_sentence_labels' column with the new values\n",
    "        annotator2_results.at[idx, 'manual_sentence_labels'] = updated_sentences\n",
    "\n",
    "# Iterate over the rows in annotator2_results again to update non-annotated sentences\n",
    "for idx, row in annotator2_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    sentences = row['manual_sentence_labels']\n",
    "    if all(isinstance(s, str) for s in sentences):\n",
    "        match = annotator2[annotator2['note_nr'] == note_nr]\n",
    "        if match.empty:\n",
    "            annotator2_results.at[idx, 'manual_sentence_labels'] = [np.nan] * len(sentences)\n",
    "\n",
    "# Update 'None' labels to np.nan in 'manual_sentence_labels'\n",
    "annotator2_results['manual_sentence_labels'] = annotator2_results['manual_sentence_labels'].apply(\n",
    "    lambda x: [np.nan if v is None else v for v in x]\n",
    ")\n",
    "\n",
    "# Replace 'WHO 0', 'WHO 1', etc. with the corresponding integer number in 'manual_sentence_labels'\n",
    "annotator2_results['manual_sentence_labels'] = annotator2_results['manual_sentence_labels'].apply(\n",
    "    lambda x: [int(v.split()[1]) if isinstance(v, str) and v.startswith(\"WHO\") else v for v in x]\n",
    ")\n",
    "\n",
    "# Copy 'manual_sentence_labels' to 'relevance_manual' and replace values\n",
    "annotator2_results['relevance_manual'] = annotator2_results['manual_sentence_labels'].apply(\n",
    "    lambda x: [0 if isinstance(v, float) and np.isnan(v) else 1 for v in x]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "annotator2_results['note_PS_manual'] = np.nan\n",
    "\n",
    "# Iterate over the rows in annotator2_results\n",
    "for idx, row in annotator2_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    # Look up the rows in annotator2 with the same note_nr\n",
    "    matches = annotator2[annotator2['note_nr'] == note_nr]\n",
    "    # Check if any of these rows contain 'report_type' in the 'sentence_text' column\n",
    "    report_type_match = matches[matches['inception_sentence'].str.contains('report_type', na=False)]\n",
    "    if not report_type_match.empty:\n",
    "        # Assign the value from the 'WHOPS' column of the first matching row to 'note_PS_manual'\n",
    "        annotator2_results.at[idx, 'note_PS_manual'] = report_type_match['WHOPS'].values[0]\n",
    "\n",
    "        \n",
    "        \n",
    "# Convert 'WHO 0', 'WHO 1', etc. in 'note_PS_manual' to their corresponding integers and ensure NaN values are np.nan\n",
    "annotator2_results['note_PS_manual'] = annotator2_results['note_PS_manual'].apply(\n",
    "    lambda x: int(x.split()[1]) if isinstance(x, str) and x.startswith(\"WHO\") else np.nan\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Copy the 'note_PS_manual' column and replace values\n",
    "annotator2_results['relevance_PS_manual'] = annotator2_results['note_PS_manual'].apply(\n",
    "    lambda x: 0 if np.isnan(x) else 1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the new column 'previous_ann' initialized with 'no'\n",
    "annotator2_results['previous_ann'] = 0\n",
    "\n",
    "# Iterate over the rows in annotator2_results\n",
    "for idx, row in annotator2_results.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    # Look up the rows in annotator1 with the same note_nr\n",
    "    matches = annotator2[annotator2['note_nr'] == note_nr]\n",
    "    # Check if any of these rows contain 'WHO PS already annotated' in the 'WHOPScat' column\n",
    "    if any(matches['WHOPScat'].str.contains('WHO PS already annotated', na=False)):\n",
    "        annotator2_results.at[idx, 'previous_ann'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d68a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotator1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator1_results = annotator1_results[annotator1_results['note_nr'].isin(note_nrs_1)]\n",
    "annotator2_results = annotator2_results[annotator2_results['note_nr'].isin(note_nrs_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(annotator1_results))\n",
    "print(len(annotator2_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator1_backup = copy.deepcopy(annotator1_results)\n",
    "annotator2_backup = copy.deepcopy(annotator2_results)\n",
    "print(annotator1_results['censored'])\n",
    "print(annotator1_results[['relevance_PS_manual', 'relevance_manual']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotator1_backup.head(2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad03600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotator1_results['relevance_PS_manual'] = annotator1_results['relevance_manual'].replace({'relevant': 1, 'irrelevant': 0})\n",
    "#annotator1_results['relevance_manual'] = annotator1_results['relevance_manual'].apply(lambda x: [1 if item == 'relevant' else 0 for item in x])\n",
    "#annotator1_results['previous_ann'] = annotator1_results['previous_ann'].replace({'relevant': 1, 'irrelevant': 0})\n",
    "\n",
    "#annotator2_results['relevance_PS_manual'] = annotator2_results['relevance_manual'].replace({'relevant': 1, 'irrelevant': 0})\n",
    "#annotator2_results['relevance_manual'] = annotator2_results['relevance_manual'].apply(lambda x: [1 if item == 'relevant' else 0 for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(annotator1_results['censored'])\n",
    "print(annotator1_results[['relevance_PS_manual', 'relevance_manual']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccac26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotator1_results.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fe7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_all = pd.concat([annotator1_results, annotator2_results], ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotator_all.to_csv('first_round_before_adjudicion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defa800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

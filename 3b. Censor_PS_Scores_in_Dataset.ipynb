{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883547c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#valtest_df1 = pd.read_csv('valtest_first_round1.csv')\n",
    "#valtest_df2 = pd.read_csv('valtest_set_extra.csv')\n",
    "#first_20 = pd.read_csv('sample_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_20 = first_20.drop(index =[3,6,7,8,16,17,18])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64463a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_20 = first_20[first_20['report_type'].isin(['Voortgangsverslag', 'MDO-verslag'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(first_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valtest = pd.read_csv('second_round_104_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valtest = pd.concat([valtest_df1,valtest_df2])\n",
    "#valtest = valtest_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = valtest.loc[valtest['set'] == 'val']\n",
    "testset = valtest.loc[valtest['set'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2222a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valset))\n",
    "print(len(testset))\n",
    "print(valset['pseudo_id'].unique())\n",
    "print(testset['pseudo_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e12fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valset['report_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41711d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testset['report_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(valtest_df1['report_type'].unique())\n",
    "#print(valtest_df2['report_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = valtest\n",
    "#The text of each note shall not contain any additional space/period. Therefore I replace most common combination of codes for line termination (\\r and \\n)\n",
    "data['pseudonomised_text']=data['pseudonomised_text'].str.replace('\\r\\n\\r\\n\\r\\n' ,'. ')\n",
    "data['pseudonomised_text']=data['pseudonomised_text'].str.replace('\\r\\n',': ')\n",
    "data['pseudonomised_text']=data['pseudonomised_text'].str.replace('\\r\\n\\r\\n\\r\\n' ,'. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[~data['note_nr'].isin(first_20['note_nr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['report_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023096d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_performance_scores(text):\n",
    "    \"\"\"\n",
    "    Finds performance scores in a given text and extracts surrounding context.\n",
    "\n",
    "    Args:\n",
    "        text: The text to search.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries containing the score type, system (for ECOG/WHO),\n",
    "        and the original surrounding context (if a match is found).\n",
    "    \"\"\"\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Define patterns to capture WHO and ECOG scores, including all variations from PS_List\n",
    "    patterns = [\n",
    "        r\"(?P<before>.{0,50})(WHO(?:[-\\s]?score[:\\s-]*)?(?:\\d+[-\\s]?\\d*)|WHO(?:-schaal)?[:\\s-]*\\d+|WHO-classificatie[:\\s-]*\\d+|ECOG[:\\s-]?\\d+[-\\s]?\\d*)(?P<after>.{0,50})\",\n",
    "        r\"(?P<before>.{0,50})(performance\\s+status\\s*(?:ECOG|WHO)\\s*\\d+)(?P<after>.{0,50})\",\n",
    "        r\"(?P<before>.{0,50})(Karnofsky[:\\s-]*\\d+)(?P<after>.{0,50})\",\n",
    "        r\"(?P<before>.{0,50})(PS(?:\\s*\\.\\s*|\\s*|\\.|\\s*PS\\s*)\\d+)(?P<after>.{0,50})\"\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        for match in re.finditer(pattern, text):\n",
    "            score_type = \"WHO\" if \"WHO\" in match.group(2) else (\"ECOG\" if \"ECOG\" in match.group(2) else \"Karnofsky\" if \"Karnofsky\" in match.group(2) else \"PS\")\n",
    "            score_system = match.group(2)\n",
    "            context = match.group(\"before\") + match.group(2) + match.group(\"after\")\n",
    "            scores.append({\n",
    "                \"type\": score_type,\n",
    "                \"system\": score_system,\n",
    "                \"context\": context\n",
    "            })\n",
    "\n",
    "    return scores\n",
    "\n",
    "def create_has_score_column(text):\n",
    "  \"\"\"\n",
    "  Checks if there's a match in the text and returns the context if a match is found,\n",
    "  otherwise returns an empty string.\n",
    "  \"\"\"\n",
    "  scores = find_performance_scores(text)\n",
    "  if scores:\n",
    "    return scores[0][\"context\"]  # Assuming only the first match is needed\n",
    "  else:\n",
    "    return \"\"\n",
    "\n",
    "# Add a new column named 'has_score' to store the context if a match is found\n",
    "data['has_score'] = data['pseudonomised_text'].apply(create_has_score_column)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "# Print the DataFrame to see the new 'has_score' column\n",
    "print('length df:', len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12415a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_convert_scores(text):\n",
    "  \"\"\"\n",
    "  Extracts scores from a string, converts them based on ranges, and removes duplicates.\n",
    "\n",
    "  Args:\n",
    "    text: The text to extract scores from.\n",
    "\n",
    "  Returns:\n",
    "    A list of unique converted scores found in the text.\n",
    "  \"\"\"\n",
    "  scores = []\n",
    "  for match in re.finditer(r\"(\\d+)\", text):\n",
    "    score_value = int(match.group())\n",
    "#     converted_value = None\n",
    "#     if (score_value == 100) or (score_value == 90) :\n",
    "#       converted_value = 0\n",
    "#     elif (score_value == 80) or (score_value == 70) :\n",
    "#       converted_value = 1\n",
    "#     elif (score_value == 60) or (score_value == 50) :\n",
    "#       converted_value = 2\n",
    "#     elif (score_value == 40) or (score_value == 30) :\n",
    "#       converted_value = 3\n",
    "#     elif (score_value == 20) or (score_value == 10) :\n",
    "#       converted_value = 4   \n",
    "#     else:  # Scores below 30 remain the same\n",
    "#       converted_value = score_value\n",
    "    converted_value = score_value\n",
    "    # Karnofsky is here not converted, because it is used to censor the file.\n",
    "\n",
    "    if converted_value is not None:\n",
    "      scores.append(converted_value)\n",
    "  return list(set(scores))  # Ensure unique elements\n",
    "\n",
    "# Create a new column named 'PS' to store the extracted and converted scores\n",
    "data['PS'] = data['has_score'].apply(extract_and_convert_scores)\n",
    "\n",
    "# Print the DataFrame to see the new 'PS' column\n",
    "print('length df:', len(data))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647aea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['has_score'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['has_score'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864bb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6f64e",
   "metadata": {},
   "source": [
    "# Censoring Performance Stati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df = data[data['has_score'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 5000\n",
    "PS_df['pseudonomised_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to check if any string in the list is present in a sentence\n",
    "#def contains_any(sentence, PS_List):\n",
    "#  return any(word in sentence for word in PS_List)\n",
    "\n",
    "# Filter rows where 'col1' contains at least one string from 'search_list'\n",
    "#PS_df = PS_df[PS_df['pseudonomised_text'].apply(lambda x: contains_any(x, PS_List))]\n",
    "\n",
    "#print(len(PS_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df['censored'] = PS_df['pseudonomised_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aca1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of strings to replace\n",
    "replace_list = PS_List\n",
    "\n",
    "# Replacement string\n",
    "replacement_string = '[WHO PS gecensureerd]'\n",
    "\n",
    "# Replace strings in 'col1' using a loop (for educational purposes)\n",
    "def replace_strings_loop(df, replace_list, replacement_string, col_name='censored'):\n",
    "  \"\"\"\n",
    "  Replaces strings in a DataFrame column using a loop.\n",
    "\n",
    "  Args:\n",
    "      df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "      replace_list (list): The list of strings to replace.\n",
    "      replacement_string (str): The string to replace the elements in 'replace_list' with.\n",
    "      col_name (str, optional): The name of the column to modify. Defaults to 'col1'.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "  \"\"\"\n",
    "  for index, row in df.iterrows():\n",
    "    # Make a copy of the row to avoid modifying the original DataFrame\n",
    "    new_row = row.copy()\n",
    "    for item in replace_list:\n",
    "      new_row[col_name] = new_row[col_name].replace(item, replacement_string)\n",
    "    df.loc[index] = new_row\n",
    "  return df\n",
    "\n",
    "# Replace strings using vectorized string methods (more efficient)\n",
    "def replace_strings_vectorized(df, replace_list, replacement_string, col_name='censored'):\n",
    "  \"\"\"\n",
    "  Replaces strings in a DataFrame column using vectorized string methods.\n",
    "\n",
    "  Args:\n",
    "      df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "      replace_list (list): The list of strings to replace.\n",
    "      replacement_string (str): The string to replace the elements in 'replace_list' with.\n",
    "      col_name (str, optional): The name of the column to modify. Defaults to 'col1'.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "  \"\"\"\n",
    "  for item in replace_list:\n",
    "    df[col_name] = df[col_name].str.replace(item, replacement_string)\n",
    "  return df\n",
    "\n",
    "# Example usage (loop method)\n",
    "#replaced_df_loop = replace_strings_loop(PS_df.copy(), replace_list.copy(), replacement_string)\n",
    "\n",
    "# Example usage (vectorized method - recommended for efficiency)\n",
    "PS_df = replace_strings_vectorized(PS_df.copy(), replace_list.copy(), replacement_string)\n",
    "print(PS_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # List of strings to replace\n",
    "# replace_list = PS_List + ['[WHO PS gecensureerd]-1']\n",
    "\n",
    "# # Replacement string\n",
    "# replacement_string = '[WHO PS gecensureerd]'\n",
    "\n",
    "# # Replace strings in 'col1' using a loop (for educational purposes)\n",
    "# def replace_strings_loop(df, replace_list, replacement_string, col_name='censored'):\n",
    "#   \"\"\"\n",
    "#   Replaces strings in a DataFrame column using a loop.\n",
    "\n",
    "#   Args:\n",
    "#       df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "#       replace_list (list): The list of strings to replace.\n",
    "#       replacement_string (str): The string to replace the elements in 'replace_list' with.\n",
    "#       col_name (str, optional): The name of the column to modify. Defaults to 'col1'.\n",
    "\n",
    "#   Returns:\n",
    "#       pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "#   \"\"\"\n",
    "#   for index, row in df.iterrows():\n",
    "#     # Make a copy of the row to avoid modifying the original DataFrame\n",
    "#     new_row = row.copy()\n",
    "#     for item in replace_list:\n",
    "#       new_row[col_name] = new_row[col_name].replace(item, replacement_string)\n",
    "#     df.loc[index] = new_row\n",
    "#   return df\n",
    "\n",
    "# # Replace strings using vectorized string methods (more efficient)\n",
    "# def replace_strings_vectorized(df, replace_list, replacement_string, col_name='censored'):\n",
    "#   \"\"\"\n",
    "#   Replaces strings in a DataFrame column using vectorized string methods.\n",
    "\n",
    "#   Args:\n",
    "#       df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "#       replace_list (list): The list of strings to replace.\n",
    "#       replacement_string (str): The string to replace the elements in 'replace_list' with.\n",
    "#       col_name (str, optional): The name of the column to modify. Defaults to 'col1'.\n",
    "\n",
    "#   Returns:\n",
    "#       pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "#   \"\"\"\n",
    "#   for item in replace_list:\n",
    "#     df[col_name] = df[col_name].str.replace(item, replacement_string)\n",
    "#   return df\n",
    "\n",
    "# #  (loop method)\n",
    "# #replaced_df_loop = replace_strings_loop(PS_df.copy(), replace_list.copy(), replacement_string)\n",
    "\n",
    "# #  (vectorized method - recommended for efficiency)\n",
    "# replaced_df_vec = replace_strings_vectorized(PS_df.copy(), replace_list.copy(), replacement_string)\n",
    "# print(replaced_df_vec)\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# List of strings to replace\n",
    "replace_list = PS_List + ['[WHO PS gecensureerd]-1']\n",
    "\n",
    "# Replacement string\n",
    "replacement_string = '[WHO PS gecensureerd]'\n",
    "\n",
    "# Replace strings using regular expressions\n",
    "def replace_strings_with_regex(df, replacement_string, col_name='censored'):\n",
    "    \"\"\"\n",
    "    Replaces strings in a DataFrame column using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "        replacement_string (str): The string to replace the matched patterns with.\n",
    "        col_name (str, optional): The name of the column to modify. Defaults to 'censored'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r\"WHO(?:[-\\s]?score[:\\s-]*)?(?:\\d+[-\\s]?\\d*)\",\n",
    "        r\"WHO(?:-schaal)?[:\\s-]*\\d+\",\n",
    "        r\"WHO-classificatie[:\\s-]*\\d+\",\n",
    "        r\"ECOG[:\\s-]?\\d+[-\\s]?\\d*\",\n",
    "        r\"performance\\s+status\\s*(?:ECOG|WHO)\\s*\\d+\",\n",
    "        r\"Karnofsky[:\\s-]*\\d+\",\n",
    "        r\"PS(?:\\s*\\.\\s*|\\s*|\\.|\\s*PS\\s*)\\d+\"\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        df[col_name] = df[col_name].str.replace(pattern, replacement_string, regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "replaced_df_vec = replace_strings_vectorized(PS_df.copy(), replace_list.copy(), replacement_string)\n",
    "print(replaced_df_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all rows with PS\n",
    "PS_df = replaced_df_vec\n",
    "# all rows without PS\n",
    "no_PS = data[~data['note_nr'].isin(PS_df['note_nr'])]\n",
    "no_PS['censored'] = no_PS['pseudonomised_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be198f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(PS_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65de287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for inter-annotator agreement\n",
    "from sklearn.utils import shuffle\n",
    "PS_df_sample = PS_df.sample(n=11)\n",
    "no_PS_df_sample = no_PS.sample(n=29)\n",
    "sample_20_a = pd.concat([PS_df_sample[:10], no_PS_df_sample[:10]])\n",
    "sample_20_b = pd.concat([PS_df_sample[10:], no_PS_df_sample[10:]])\n",
    "#sample_40 = pd.concat([PS_df_sample, no_PS_df_sample])\n",
    "#sample_40 = shuffle(sample_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af407a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sample_20_a))\n",
    "print(len(sample_20_b))\n",
    "print(sample_20_a['note_nr'].unique())\n",
    "print(sample_20_b['note_nr'].unique())\n",
    "print(sample_20_a['has_score'])\n",
    "print(sample_20_b['has_score'])\n",
    "print(sample_20_a['censored'])\n",
    "print(sample_20_b['censored'])\n",
    "sample_20_a = shuffle(sample_20_a)\n",
    "sample_20_b = shuffle(sample_20_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98799c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "first_round = pd.concat([PS_df, no_PS])\n",
    "first_round = shuffle(first_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of strings to replace\n",
    "replace_list = PS_List\n",
    "\n",
    "# Replacement string\n",
    "replacement_string = '[WHO PS gecensureerd]'\n",
    "\n",
    "# Replace strings in 'col1' using a loop (for educational purposes)\n",
    "def replace_strings_loop(df, replace_list, replacement_string, col_name='censored'):\n",
    "  \"\"\"\n",
    "  Replaces strings in a DataFrame column using a loop.\n",
    "\n",
    "  Args:\n",
    "      df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "      replace_list (list): The list of strings to replace.\n",
    "      replacement_string (str): The string to replace the elements in 'replace_list' with.\n",
    "      col_name (str, optional): The name of the column to modify. Defaults to 'col1'.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "  \"\"\"\n",
    "  for index, row in df.iterrows():\n",
    "    # Make a copy of the row to avoid modifying the original DataFrame\n",
    "    new_row = row.copy()\n",
    "    for item in replace_list:\n",
    "      new_row[col_name] = new_row[col_name].replace(item, replacement_string)\n",
    "    df.loc[index] = new_row\n",
    "  return df\n",
    "\n",
    "# Replace strings using vectorized string methods (more efficient)\n",
    "def replace_strings_vectorized(df, replace_list, replacement_string, col_name='censored'):\n",
    "  \"\"\"\n",
    "  Replaces strings in a DataFrame column using vectorized string methods.\n",
    "\n",
    "  Args:\n",
    "      df (pandas.DataFrame): The DataFrame containing the column to modify.\n",
    "      replace_list (list): The list of strings to replace.\n",
    "      replacement_string (str): The string to replace the elements in 'replace_list' with.\n",
    "      col_name (str, optional): The name of the column to modify. Defaults to 'col1'.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: The DataFrame with the replacements applied.\n",
    "  \"\"\"\n",
    "  for item in replace_list:\n",
    "    df[col_name] = df[col_name].str.replace(item, replacement_string)\n",
    "  return df\n",
    "\n",
    "# Example usage (loop method)\n",
    "#replaced_df_loop = replace_strings_loop(PS_df.copy(), replace_list.copy(), replacement_string)\n",
    "\n",
    "# Example usage (vectorized method - recommended for efficiency)\n",
    "first_round = replace_strings_vectorized(first_round.copy(), replace_list.copy(), replacement_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236c633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c49ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sample_40['censored'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c55fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_round = first_round[~first_round['note_nr'].isin(sample_20_a['note_nr'])]\n",
    "first_round = first_round[~first_round['note_nr'].isin(sample_20_b['note_nr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(first_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e262c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for annotators\n",
    "subset_size = int(len(first_round)/2)\n",
    "data_ann1 = first_round.sample(n=subset_size,random_state =1)\n",
    "data_ann2 = first_round.drop(data_ann1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18563ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26277e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 20b is used for second inter-annotator agreement-moment\n",
    "first_round_ann1 = pd.concat([data_ann1, sample_20_b], ignore_index=True)\n",
    "first_round_ann2 = pd.concat([data_ann2, sample_20_b], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(first_round))\n",
    "print(first_round['note_nr'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74883bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_round[first_round['censored'].str.contains('WHO', case=False, na=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec20178",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_round_ann1['note_nr'].tail(30))\n",
    "print(first_round_ann2['note_nr'].tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a961af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_round_ann1['censored'].tail(30))\n",
    "print(first_round_ann2['censored'].tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "first_round_ann1.to_csv('first_round_ann1_allcol.csv')\n",
    "first_round_ann2.to_csv('first_round_ann2_allcol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_round_ann1 = first_round_ann1[['note_nr', 'report_type', 'censored', 'set']]\n",
    "first_round_ann2 = first_round_ann2[['note_nr', 'report_type', 'censored', 'set']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d98207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_20_a['censored'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafd63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_20_a = sample_20_a[['note_nr', 'report_type', 'censored']]\n",
    "#sample_20_a.to_csv('sample_20_iaa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39192f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r\"C:\\Users\\Nynke (A193DBBA)\\Desktop\\\\Second_round\"\n",
    "first_round_ann2 = pd.concat([first_round_ann2, first_round_ann1[:10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in first_round_ann1.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    row.to_csv(f'{directory_path}ann1_file_{note_nr}', sep='.')\n",
    "    \n",
    "for index, row in first_round_ann2.iterrows():\n",
    "    note_nr = row['note_nr']\n",
    "    row.to_csv(f'{directory_path}ann2_file_{note_nr}', sep='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in sample_20_a.iterrows():\n",
    "#    row.to_csv(f'{dir_path}\\iaa-file{index}', sep='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e466eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PS_df['censored'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c60c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(first_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4864200",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_round_ann2 = pd.concat([first_round_ann2, first_round_ann1[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009af4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(first_round_ann1))\n",
    "print(len(first_round_ann2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149555db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681141d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(first_round_ann1['note_nr']).intersection(set(first_round_ann2['note_nr'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_round_ann1.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import Levenshtein as lev\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fa095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf41e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create list of all structured files (from EPIC) and list with names of files\n",
    "print('start0')\n",
    "path_to_dir=r'Z:\\final EPIC data 20220909\\*.xlsx'\n",
    "list_files=glob.glob(path_to_dir)\n",
    "data_all=[]\n",
    "file_name=[]\n",
    "print('start1')\n",
    "print(len(list_files))\n",
    "for j in range(0,len(list_files)):\n",
    "    print('j:', j)\n",
    "    data_all.append(pd.read_excel(list_files[j]))\n",
    "    file_name.append(list_files[j][32:-5])\n",
    "\n",
    "print('start2')\n",
    "##Read NKR registry data\n",
    "NKR_data=pd.read_csv(r\"Z:\\IKNL data\\IKNL data update\\K21186.csv\", delimiter=';')\n",
    "\n",
    "print('start3')\n",
    "##Read tables with mapping between Patient ID (from the structured files) to the pseudoID of the clinical notes\n",
    "AMC_conv=pd.read_excel(r\"Z:\\final EPIC data 20220909\\Text data 6-10-2022\\002a AMC CTcue import-results-2022-09-12.xlsx\")\n",
    "VUmc_conv=pd.read_excel(r\"Z:\\final EPIC data 20220909\\Text data 6-10-2022\\002b VUmc CTcue import-results-2022-09-09.xlsx\")\n",
    "\n",
    "print('start4')\n",
    "##Read clinical notes from location AMC and location VUmc\n",
    "notes_AMC=pd.read_csv(r\"Z:\\final EPIC data 20220909\\Text data 6-10-2022\\amc_data_aanvraag_20221004_aangepast.csv\", encoding=\"utf-16\")\n",
    "notes_VUmc=pd.read_csv(r\"Z:\\final EPIC data 20220909\\Text data 6-10-2022\\vumc_data_aanvraag_20221004_aangepast.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c05d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_AMC['pseudonomised_text']=notes_AMC['pseudonomised_text'].str.replace('\\r\\n\\r\\n\\r\\n' ,'. ')\n",
    "notes_AMC['pseudonomised_text']=notes_AMC['pseudonomised_text'].str.replace('\\r\\n\\r\\n','. ')\n",
    "notes_AMC['pseudonomised_text']=notes_AMC['pseudonomised_text'].str.replace('\\r\\n',': ')\n",
    "notes_VUmc['pseudonomised_text']=notes_VUmc['pseudonomised_text'].str.replace('\\r\\n\\r\\n\\r\\n' ,'. ')\n",
    "notes_VUmc['pseudonomised_text']=notes_VUmc['pseudonomised_text'].str.replace('\\r\\n\\r\\n','. ')\n",
    "notes_VUmc['pseudonomised_text']=notes_VUmc['pseudonomised_text'].str.replace('\\r\\n',': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ca648",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_VU = 0\n",
    "\n",
    "# Define the fuzzy pattern with dynamic Levenshtein distance for individual words\n",
    "pattern = r'(?i)\\b(?:WHO|ECOG|Performance)\\s*(?:PS|Status|Score)\\b'\n",
    "\n",
    "# Define a function to calculate the maximum Levenshtein distance for individual words\n",
    "def max_levenshtein_distance(word):\n",
    "    length = len(word)\n",
    "    if length <= 5:\n",
    "        return 1  # Allow small variations for short words\n",
    "    else:\n",
    "        return min(7, int(length * 0.4))  # Adjust the threshold for longer words\n",
    "\n",
    "df = notes_VUmc   \n",
    "    \n",
    "# Replace non-breaking spaces with regular spaces\n",
    "df['pseudonomised_text'] = df['pseudonomised_text'].str.replace(u'\\u00a0', ' ')\n",
    "\n",
    "# Iterate over the DataFrame and print the notes that match the pattern\n",
    "for index, row in df.iterrows():\n",
    "    text = row['pseudonomised_text']\n",
    "    words = re.findall(r'\\b\\w+\\b', text)  # Extract words for Levenshtein distance calculation\n",
    "    matches = []\n",
    "    for word in words:\n",
    "        max_distance = max_levenshtein_distance(word)\n",
    "        if any(lev.distance(word.lower(), term.lower()) <= max_distance for term in ['performance', 'status']):\n",
    "            matches.append(word)\n",
    "    if matches:\n",
    "        #print(text)\n",
    "        matches_VU +=1\n",
    "        \n",
    "print('total:', matches_VU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_AMC = 0\n",
    "\n",
    "# Define the fuzzy pattern with dynamic Levenshtein distance for individual words\n",
    "pattern = r'(?i)\\b(?:WHO|ECOG|Performance)\\s*(?:PS|Status|Score)\\b'\n",
    "\n",
    "# Define a function to calculate the maximum Levenshtein distance for individual words\n",
    "def max_levenshtein_distance(word):\n",
    "    length = len(word)\n",
    "    if length <= 5:\n",
    "        return 1  # Allow small variations for short words\n",
    "    else:\n",
    "        return min(7, int(length * 0.4))  # Adjust the threshold for longer words\n",
    "\n",
    "df = notes_AMC   \n",
    "    \n",
    "# Replace non-breaking spaces with regular spaces\n",
    "df['pseudonomised_text'] = df['pseudonomised_text'].str.replace(u'\\u00a0', ' ')\n",
    "\n",
    "# Iterate over the DataFrame and print the notes that match the pattern\n",
    "for index, row in df.iterrows():\n",
    "    text = row['pseudonomised_text']\n",
    "    words = re.findall(r'\\b\\w+\\b', text)  # Extract words for Levenshtein distance calculation\n",
    "    matches = []\n",
    "    for word in words:\n",
    "        max_distance = max_levenshtein_distance(word)\n",
    "        if any(lev.distance(word.lower(), term.lower()) <= max_distance for term in ['performance', 'status']):\n",
    "            matches.append(word)\n",
    "    if matches:\n",
    "        #print(text)\n",
    "        matches_AMC +=1\n",
    "        \n",
    "print('total:', matches_AMC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_performance_scores(text):\n",
    "  \"\"\"\n",
    "  Finds performance scores in a given text and extracts surrounding context.\n",
    "\n",
    "  Args:\n",
    "    text: The text to search.\n",
    "\n",
    "  Returns:\n",
    "    A list of dictionaries containing the score type, system (for ECOG/WHO),\n",
    "    and the original surrounding context (if a match is found).\n",
    "  \"\"\"\n",
    "\n",
    "  scores = []\n",
    "\n",
    "  # Performance score (ECOG or WHO)\n",
    "  pattern = r\"(?P<before>.{0,50})((?:ECOG|WHO)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"performance\",\n",
    "      \"system\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  # Performance status (ECOG or WHO)\n",
    "  pattern = r\"(?P<before>.{0,50})((?:performance\\s+status|status)\\s*(?:ECOG|WHO)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"performance_status\",\n",
    "      \"system\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  # Karnofsky score\n",
    "  pattern = r\"(?P<before>.{0,50})((?:Karnofsky|KPS)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"karnofsky\",\n",
    "      \"score\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  # PS score\n",
    "  pattern = r\"(?P<before>.{0,50})((?:PS|P\\.S\\.|PS\\.)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"ps\",\n",
    "      \"score\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  return scores\n",
    "\n",
    "def create_has_score_column(text):\n",
    "  \"\"\"\n",
    "  Checks if there's a match in the text and returns the context if a match is found,\n",
    "  otherwise returns an empty string.\n",
    "  \"\"\"\n",
    "  scores = find_performance_scores(text)\n",
    "  if scores:\n",
    "    return scores[0][\"context\"]  # Assuming only the first match is needed\n",
    "  else:\n",
    "    return \"\"\n",
    "\n",
    "# Add a new column named 'has_score' to store the context if a match is found\n",
    "notes_VUmc['has_score'] = notes_VUmc['pseudonomised_text'].apply(create_has_score_column)\n",
    "\n",
    "# Print the DataFrame to see the new 'has_score' column\n",
    "print(notes_VUmc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891560bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_VUmc['has_score'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in notes_VUmc['has_score']:\n",
    "    if len(text) > 1:\n",
    "        print('')\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_performance_scores(text):\n",
    "  \"\"\"\n",
    "  Finds performance scores in a given text and extracts surrounding context.\n",
    "\n",
    "  Args:\n",
    "    text: The text to search.\n",
    "\n",
    "  Returns:\n",
    "    A list of dictionaries containing the score type, system (for ECOG/WHO),\n",
    "    and the original surrounding context (if a match is found).\n",
    "  \"\"\"\n",
    "\n",
    "  scores = []\n",
    "\n",
    "  # Performance score (ECOG or WHO)\n",
    "  pattern = r\"(?P<before>.{0,50})((?:ECOG|WHO)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"performance\",\n",
    "      \"system\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  # Performance status (ECOG or WHO)\n",
    "  pattern = r\"(?P<before>.{0,50})((?:performance\\s+status|status)\\s*(?:ECOG|WHO)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"performance_status\",\n",
    "      \"system\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  # Karnofsky score\n",
    "  pattern = r\"(?P<before>.{0,50})((?:Karnofsky|KPS)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"karnofsky\",\n",
    "      \"score\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  # PS score\n",
    "  pattern = r\"(?P<before>.{0,50})((?:PS|P\\.S\\.|PS\\.)\\s*(\\d+))(?:(?P<after>.{0,50})|$)\"\n",
    "  for match in re.finditer(pattern, text):\n",
    "    scores.append({\n",
    "      \"type\": \"ps\",\n",
    "      \"score\": match.group(3),\n",
    "      \"context\": match.group(\"before\") + match.group(0) + match.group(\"after\")\n",
    "    })\n",
    "\n",
    "  return scores\n",
    "\n",
    "def create_has_score_column(text):\n",
    "  \"\"\"\n",
    "  Checks if there's a match in the text and returns the context if a match is found,\n",
    "  otherwise returns an empty string.\n",
    "  \"\"\"\n",
    "  scores = find_performance_scores(text)\n",
    "  if scores:\n",
    "    return scores[0][\"context\"]  # Assuming only the first match is needed\n",
    "  else:\n",
    "    return \"\"\n",
    "\n",
    "# Add a new column named 'has_score' to store the context if a match is found\n",
    "notes_AMC['has_score'] = notes_AMC['pseudonomised_text'].apply(create_has_score_column)\n",
    "\n",
    "# Print the DataFrame to see the new 'has_score' column\n",
    "print(notes_AMC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_AMC['has_score'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in notes_AMC['has_score']:\n",
    "    if len(text) > 1:\n",
    "        print('')\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8138ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_AMC['has_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(notes_AMC[notes_AMC['pseudonomised_text'].str.contains('PS')]['pseudonomised_text'])\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec5ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

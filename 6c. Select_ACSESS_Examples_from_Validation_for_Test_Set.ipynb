{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folds = pd.read_csv('folds_val.csv', sep = '\\t')\n",
    "val_folds_validated = pd.read_csv('val_folds_validated.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfcdefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_folds_validated))\n",
    "print(len(folds))\n",
    "\n",
    "#examples = folds[folds['fold']==\"examples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folds['sentence'].head())\n",
    "print(val_folds_validated['sentence'].head())\n",
    "folds['validated'] = val_folds_validated['validated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = folds[folds['relevance_manual'] == folds['validated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examples = folds[folds['fold'] != fold]\n",
    "examples = folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples.columns)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab502dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564b96b",
   "metadata": {},
   "source": [
    "# Select examples for binary task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples[examples['relevance_manual'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming df is already defined as your DataFrame with Dutch sentences and labels\n",
    "\n",
    "# Extract sentences and labels\n",
    "sentences = examples['sentence'].values\n",
    "labels = examples['relevance_manual'].values\n",
    "\n",
    "# Convert labels to numeric (including np.nan as a distinct label)\n",
    "unique_labels = pd.Series(labels).unique()\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# ========== Feature Extraction ==========\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# Reduce dimensionality for better clustering (optional)\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "X_reduced = pca.fit_transform(X)  # Now X_reduced is defined\n",
    "\n",
    "# Adjusted functions from previous code\n",
    "def similarity_selection(X, y, k):\n",
    "    \"\"\"Selects samples that are most similar to the centroid of the class.\"\"\"\n",
    "    centroids = []\n",
    "    for i in np.unique(y):\n",
    "        if np.sum(y == i) > 0:\n",
    "            centroid = np.mean(X[y == i], axis=0)\n",
    "            centroids.append(centroid)\n",
    "        else:\n",
    "            centroids.append(None)\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(len(centroids)):\n",
    "        if centroids[i] is not None:\n",
    "            sim = np.linalg.norm(X[y == i] - centroids[i], axis=1)\n",
    "            most_similar_idx = np.argsort(sim)[:min(k, len(sim))]\n",
    "            similarities.append(most_similar_idx)\n",
    "    \n",
    "    return np.concatenate(similarities) if similarities else np.array([])\n",
    "\n",
    "def diversity_selection_simple(X, y, k):\n",
    "    \"\"\"Selects the most diverse samples based on pairwise distances.\"\"\"\n",
    "    diverse_samples_idx = []\n",
    "    for i in np.unique(y):\n",
    "        if np.sum(y == i) > 0:\n",
    "            pairwise_dists = pairwise_distances(X[y == i])\n",
    "            diverse_samples = np.argsort(np.mean(pairwise_dists, axis=1))[-min(k, len(pairwise_dists)):]\n",
    "            diverse_samples_idx.append(diverse_samples)\n",
    "    \n",
    "    return np.concatenate(diverse_samples_idx) if diverse_samples_idx else np.array([])\n",
    "\n",
    "def learnability_selection(X, y, k):\n",
    "    \"\"\"Simulates learnability by selecting samples with lower variance in feature space.\"\"\"\n",
    "    variances = np.var(X, axis=1)\n",
    "    learnable_samples_idx = []\n",
    "    for i in np.unique(y):\n",
    "        if np.sum(y == i) > 0:\n",
    "            learnable_samples_idx.append(np.argsort(variances[y == i])[:min(k, len(variances[y == i]))])\n",
    "    \n",
    "    return np.concatenate(learnable_samples_idx) if learnable_samples_idx else np.array([])\n",
    "\n",
    "def acsess(X, y, weights, k):\n",
    "    \"\"\"Combine the different strategies with specified weights.\"\"\"\n",
    "    combined_scores = np.zeros(len(X))\n",
    "    \n",
    "    # Similarity selection\n",
    "    sim_idx = similarity_selection(X, y, k)\n",
    "    combined_scores[sim_idx] += weights['similarity']\n",
    "    \n",
    "    # Diversity selection (using simple distance-based method)\n",
    "    div_idx = diversity_selection_simple(X, y, k)\n",
    "    combined_scores[div_idx] += weights['diversity']\n",
    "    \n",
    "    # Learnability selection\n",
    "    learn_idx = learnability_selection(X, y, k)\n",
    "    combined_scores[learn_idx] += weights['learnability']\n",
    "    \n",
    "    # Select top K samples for each class based on combined scores\n",
    "    top_samples_idx = []\n",
    "    for i in np.unique(y):\n",
    "        class_indices = np.where(y == i)[0]\n",
    "        if len(class_indices) > 0:\n",
    "            class_scores = combined_scores[class_indices]\n",
    "            top_samples_idx.append(class_indices[np.argsort(class_scores)[-min(k, len(class_scores)):]])\n",
    "    \n",
    "    return np.concatenate(top_samples_idx) if top_samples_idx else np.array([])\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "df_bin_examples = pd.DataFrame(columns=[\"example\", \"label\", \"k\"])\n",
    "\n",
    "# Example usage of ACSESS with simple diversity\n",
    "weights = {'similarity': 0.3, 'diversity': 0.4, 'learnability': 0.3}\n",
    "\n",
    "for k in range(1, 6):\n",
    "    selected_samples_idx = acsess(X_reduced, numeric_labels, weights, k)\n",
    "    selected_sentences = [sentences[i] for i in selected_samples_idx]\n",
    "    selected_labels = numeric_labels[selected_samples_idx]\n",
    "\n",
    "    # Create a temporary DataFrame for this value of k\n",
    "    temp_df = pd.DataFrame({\n",
    "        \"example\": selected_sentences,\n",
    "        \"label\": [unique_labels[label] for label in selected_labels],\n",
    "        \"k\": k\n",
    "    })\n",
    "    \n",
    "    # Append the temporary DataFrame to the results DataFrame\n",
    "    df_bin_examples = pd.concat([df_bin_examples, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49dad10",
   "metadata": {},
   "source": [
    "# Selection examples classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_classes = examples[examples['relevance_manual'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(examples_classes))\n",
    "print(examples_classes['manual_sentence_labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming df is already defined as your DataFrame with Dutch sentences and labels\n",
    "\n",
    "# Extract sentences and labels\n",
    "sentences = examples_classes['sentence'].values\n",
    "labels = examples_classes['manual_sentence_labels'].values\n",
    "\n",
    "# Convert labels to numeric (including np.nan as a distinct label)\n",
    "unique_labels = pd.Series(labels).unique()\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# ========== Feature Extraction ==========\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# Reduce dimensionality for better clustering (optional)\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "X_reduced = pca.fit_transform(X)  # Now X_reduced is defined\n",
    "\n",
    "# Adjusted functions from previous code\n",
    "def similarity_selection(X, y, k):\n",
    "    \"\"\"Selects samples that are most similar to the centroid of the class.\"\"\"\n",
    "    centroids = []\n",
    "    for i in np.unique(y):\n",
    "        if np.sum(y == i) > 0:\n",
    "            centroid = np.mean(X[y == i], axis=0)\n",
    "            centroids.append(centroid)\n",
    "        else:\n",
    "            centroids.append(None)\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(len(centroids)):\n",
    "        if centroids[i] is not None:\n",
    "            sim = np.linalg.norm(X[y == i] - centroids[i], axis=1)\n",
    "            most_similar_idx = np.argsort(sim)[:min(k, len(sim))]\n",
    "            similarities.append(most_similar_idx)\n",
    "    \n",
    "    return np.concatenate(similarities) if similarities else np.array([])\n",
    "\n",
    "def diversity_selection_simple(X, y, k):\n",
    "    \"\"\"Selects the most diverse samples based on pairwise distances.\"\"\"\n",
    "    diverse_samples_idx = []\n",
    "    for i in np.unique(y):\n",
    "        if np.sum(y == i) > 0:\n",
    "            pairwise_dists = pairwise_distances(X[y == i])\n",
    "            diverse_samples = np.argsort(np.mean(pairwise_dists, axis=1))[-min(k, len(pairwise_dists)):]\n",
    "            diverse_samples_idx.append(diverse_samples)\n",
    "    \n",
    "    return np.concatenate(diverse_samples_idx) if diverse_samples_idx else np.array([])\n",
    "\n",
    "def learnability_selection(X, y, k):\n",
    "    \"\"\"Simulates learnability by selecting samples with lower variance in feature space.\"\"\"\n",
    "    variances = np.var(X, axis=1)\n",
    "    learnable_samples_idx = []\n",
    "    for i in np.unique(y):\n",
    "        if np.sum(y == i) > 0:\n",
    "            learnable_samples_idx.append(np.argsort(variances[y == i])[:min(k, len(variances[y == i]))])\n",
    "    \n",
    "    return np.concatenate(learnable_samples_idx) if learnable_samples_idx else np.array([])\n",
    "\n",
    "def acsess(X, y, weights, k):\n",
    "    \"\"\"Combine the different strategies with specified weights.\"\"\"\n",
    "    combined_scores = np.zeros(len(X))\n",
    "    \n",
    "    # Similarity selection\n",
    "    sim_idx = similarity_selection(X, y, k)\n",
    "    combined_scores[sim_idx] += weights['similarity']\n",
    "    \n",
    "    # Diversity selection (using simple distance-based method)\n",
    "    div_idx = diversity_selection_simple(X, y, k)\n",
    "    combined_scores[div_idx] += weights['diversity']\n",
    "    \n",
    "    # Learnability selection\n",
    "    learn_idx = learnability_selection(X, y, k)\n",
    "    combined_scores[learn_idx] += weights['learnability']\n",
    "    \n",
    "    # Select top K samples for each class based on combined scores\n",
    "    top_samples_idx = []\n",
    "    for i in np.unique(y):\n",
    "        class_indices = np.where(y == i)[0]\n",
    "        if len(class_indices) > 0:\n",
    "            class_scores = combined_scores[class_indices]\n",
    "            top_samples_idx.append(class_indices[np.argsort(class_scores)[-min(k, len(class_scores)):]])\n",
    "    \n",
    "    return np.concatenate(top_samples_idx) if top_samples_idx else np.array([])\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "df_class_examples = pd.DataFrame(columns=[\"example\", \"label\", \"k\"])\n",
    "\n",
    "# Example usage of ACSESS with simple diversity\n",
    "weights = {'similarity': 0.3, 'diversity': 0.4, 'learnability': 0.3}\n",
    "\n",
    "for k in range(1, 6):\n",
    "    selected_samples_idx = acsess(X_reduced, numeric_labels, weights, k)\n",
    "    selected_sentences = [sentences[i] for i in selected_samples_idx]\n",
    "    selected_labels = numeric_labels[selected_samples_idx]\n",
    "\n",
    "    # Create a temporary DataFrame for this value of k\n",
    "    temp_df = pd.DataFrame({\n",
    "        \"example\": selected_sentences,\n",
    "        \"label\": [unique_labels[label] for label in selected_labels],\n",
    "        \"k\": k\n",
    "    })\n",
    "    \n",
    "    # Append the temporary DataFrame to the results DataFrame\n",
    "    df_class_examples = pd.concat([df_class_examples, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6737a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bin_examples.to_csv('df_bin_examples_acsess.csv', sep='\\t')\n",
    "#df_class_examples.to_csv('df_class_examples_acsess.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bin_examples.to_csv(f'ACSESS examples per fold/df_bin_examples_acsess_{fold}.csv', sep='\\t')\n",
    "#df_class_examples.to_csv(f'ACSESS examples per fold/df_class_examples_acsess_{fold}.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b5d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_examples.to_csv('df_bin_examples_acsess_for_test.csv', sep='\\t')\n",
    "df_class_examples.to_csv('df_class_examples_acsess_for_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed23573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c9744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
